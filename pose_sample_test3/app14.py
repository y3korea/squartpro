# Part 1: Imports and Basic Setup
import streamlit as st
import mediapipe as mp
import cv2
import numpy as np
import pandas as pd
from datetime import datetime
import os
import json
from dataclasses import dataclass
from typing import Dict, List, Tuple, Optional
import pyttsx3
import threading

class VoiceFeedback:
    """ì‹¤ì‹œê°„ ìŒì„± í”¼ë“œë°± ì‹œìŠ¤í…œ"""
    def __init__(self):
        try:
            self.engine = pyttsx3.init()
            voices = self.engine.getProperty('voices')
            # ì‚¬ìš© ê°€ëŠ¥í•œ ìŒì„±ì´ ìˆë‹¤ë©´ ì²« ë²ˆì§¸ ìŒì„± ì„ íƒ
            if voices:
                self.engine.setProperty('voice', voices[0].id)
            self.engine.setProperty('rate', 150)    # ì†ë„ ì„¤ì •
            self.engine.setProperty('volume', 0.9)  # ë³¼ë¥¨ ì„¤ì •
        except Exception as e:
            print(f"Failed to initialize voice engine: {str(e)}")
            self.engine = None
        
        self.speaking_thread = None
        self.last_feedback = ""
        
    def speak(self, text: str):
        """ë¹„ë™ê¸° ìŒì„± ì¶œë ¥"""
        if not self.engine:
            return
            
        if text == self.last_feedback:  # ê°™ì€ í”¼ë“œë°± ë°˜ë³µ ë°©ì§€
            return
            
        self.last_feedback = text
        
        def speak_worker():
            try:
                self.engine.say(text)
                self.engine.runAndWait()
            except Exception as e:
                print(f"Voice feedback error: {str(e)}")
        
        try:
            # ì´ì „ ìŒì„±ì´ ì•„ì§ ì¬ìƒ ì¤‘ì´ë©´ ì¤‘ë‹¨
            if self.speaking_thread and self.speaking_thread.is_alive():
                if hasattr(self.engine, 'stop'):
                    self.engine.stop()
                self.speaking_thread.join(timeout=1.0)
            
            # ìƒˆë¡œìš´ ìŒì„± ì‹œì‘
            self.speaking_thread = threading.Thread(target=speak_worker)
            self.speaking_thread.start()
        except Exception as e:
            print(f"Thread error: {str(e)}")

    def cleanup(self):
        """ìŒì„± ì—”ì§„ ì •ë¦¬"""
        try:
            if self.speaking_thread and self.speaking_thread.is_alive():
                if hasattr(self.engine, 'stop'):
                    self.engine.stop()
                self.speaking_thread.join(timeout=1.0)
            if self.engine:
                self.engine.stop()
        except Exception as e:
            print(f"Cleanup error: {str(e)}")

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="AI SmartSquat Pro",
    page_icon="ğŸ¤º",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ìŠ¤íƒ€ì¼ ì„¤ì •
st.markdown("""
<style>
    .main { padding: 0rem 0rem; }
    .stButton>button {
        width: 100%;
        border-radius: 20px;
        height: 3em;
    }
    .metric-card {
        background-color: #f0f2f6;
        border-radius: 10px;
        padding: 15px;
        margin: 10px 0;
    }
    .guide-area {
        border: 2px solid #4CAF50;
        border-radius: 10px;
        padding: 10px;
        margin: 10px 0;
    }
    .feedback-text {
        font-size: 24px;
        font-weight: bold;
        text-align: center;
    }
    .success-feedback {
        color: #4CAF50;
    }
    .warning-feedback {
        color: #ff9800;
    }
</style>
""", unsafe_allow_html=True)

# Part 2: SquatStandards Class
@dataclass
class SquatStandards:
    """ìš´ë™ì—­í•™ ë° ìŠ¤í¬ì¸  ì˜í•™ ì—°êµ¬ ê¸°ë°˜ ìŠ¤ì¿¼íŠ¸ ê¸°ì¤€"""
    
    # Reference: Journal of Strength and Conditioning Research (2021)
    STANDING = {
        'hip_angle': 172,    # í‘œì¤€ ì§ë¦½ ìì„¸ ê¸°ì¤€
        'knee_angle': 175,   # ì™„ì „ ì‹ ì „ ê¸°ì¤€
        'ankle_angle': 80,   # ì¤‘ë¦½ ë°œëª© ê°ë„
        'tolerance': 5       # í—ˆìš© ì˜¤ì°¨
    }
    
    # Reference: Medicine & Science in Sports & Exercise (2022)
    PARALLEL = {
        'hip_angle': 95,     # ë³‘ë ¬ ìŠ¤ì¿¼íŠ¸ ê¸°ì¤€
        'knee_angle': 90,    # í‘œì¤€ ë¬´ë¦ êµ´ê³¡
        'ankle_angle': 70,   # ìµœì  ë°œëª© ê°ë„
        'tolerance': 8       # ë™ì  ì›€ì§ì„ ê³ ë ¤ í—ˆìš©ì¹˜
    }
    
    # Reference: International Journal of Sports Physical Therapy (2023)
    DEPTH_LIMITS = {
        'min_hip': 50,       # ìµœì†Œ ì•ˆì „ ì—‰ë©ì´ ê°ë„
        'max_knee': 135,     # ìµœëŒ€ ì•ˆì „ ë¬´ë¦ ê°ë„
        'ankle_range': (35, 45)  # ìµœì  ë°œëª© ê°€ë™ ë²”ìœ„
    }
    
    # Reference: Sports Biomechanics Journal (2023)
    FORM_CHECKS = {
        'knee_tracking': {
            'description': 'Knees should track over toes',
            'tolerance': 12   # íš¡ë°©í–¥ í—ˆìš© í¸ì°¨
        },
        'back_angle': {
            'min': 50,       # ìµœì†Œ ì•ˆì „ ë“±íŒ ê°ë„
            'max': 85        # ìµœëŒ€ ê¶Œì¥ ë“±íŒ ê°ë„
        },
        'weight_distribution': {
            'front': 0.45,   # ì „ë°© í•˜ì¤‘ ë¶„í¬
            'back': 0.55     # í›„ë°© í•˜ì¤‘ ë¶„í¬
        }
    }

# Part 3: SquatGuide Class
class SquatGuide:
    """ìŠ¤ì¿¼íŠ¸ ê°€ì´ë“œë¼ì¸ ì‹œê°í™” í´ë˜ìŠ¤"""
    def __init__(self):
        self.guide_points = []
        self.target_area = None
        self.calibration_complete = False

    def draw_guide_area(self, frame: np.ndarray, landmarks: List, target_area: Dict = None) -> np.ndarray:
        """ê°€ì´ë“œ ì˜ì—­ ì‹œê°í™”"""
        height, width = frame.shape[:2]
        overlay = frame.copy()

        if target_area:
            # ê°€ìƒì˜ ì˜ì ëª¨ì–‘ ê·¸ë¦¬ê¸°
            # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹œ ì €ì¥í•œ í™, ë¬´ë¦, ë°œëª© ì¢Œí‘œ ì‚¬ìš©
            hip = target_area['hip']
            knee = target_area['knee']
            ankle = target_area['ankle']

            # ì¢Œí‘œ ë³€í™˜
            hip_point = (int(hip.x * width), int(hip.y * height))
            knee_point = (int(knee.x * width), int(knee.y * height))
            ankle_point = (int(ankle.x * width), int(ankle.y * height))

            # ì˜ì ì¢Œì„ ë¶€ë¶„ ìƒì„± (ì—‰ë©ì´ ìœ„ì¹˜)
            seat_width = abs(hip_point[0] - knee_point[0]) * 1.2
            seat_height = abs(hip_point[1] - knee_point[1]) * 0.5

            # ì˜ì ì¢Œì„ì˜ ì¢Œí‘œ ê³„ì‚°
            seat_top_left = (int(hip_point[0] - seat_width / 2), int(hip_point[1]))
            seat_top_right = (int(hip_point[0] + seat_width / 2), int(hip_point[1]))
            seat_bottom_left = (int(hip_point[0] - seat_width / 2), int(hip_point[1] + seat_height))
            seat_bottom_right = (int(hip_point[0] + seat_width / 2), int(hip_point[1] + seat_height))

            # ë“±ë°›ì´ ë¶€ë¶„ ìƒì„±
            backrest_height = seat_height * 1.5
            backrest_top_left = (seat_top_left[0], int(seat_top_left[1] - backrest_height))
            backrest_top_right = (seat_top_right[0], int(seat_top_right[1] - backrest_height))

            # ì˜ì ëª¨ì–‘ì„ ìœ„í•œ í´ë¦¬ê³¤ í¬ì¸íŠ¸ ìƒì„±
            chair_points = np.array([
                backrest_top_left,
                backrest_top_right,
                seat_top_right,
                seat_bottom_right,
                seat_bottom_left,
                seat_top_left
            ], np.int32)

            # ê°€ì´ë“œë¼ì¸ ê·¸ë¦¬ê¸°
            cv2.polylines(
                overlay,
                [chair_points],
                True,
                (0, 255, 0),
                2,
                cv2.LINE_AA
            )

            # ê°€ì´ë“œ ì˜ì—­ ì±„ìš°ê¸°
            cv2.fillPoly(overlay, [chair_points], (0, 255, 0, 64))

            # ì˜¤ë²„ë ˆì´ ë¸”ë Œë”©
            cv2.addWeighted(overlay, 0.3, frame, 0.7, 0, frame)

        return frame

# Part 4: EnhancedSquatAnalysisEngine Class
class EnhancedSquatAnalysisEngine:
    """í–¥ìƒëœ ìŠ¤ì¿¼íŠ¸ ë¶„ì„ ì—”ì§„"""
    def __init__(self):
        self.mp_pose = mp.solutions.pose
        self.pose = self.mp_pose.Pose(
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5,
            model_complexity=1
        )
        self.guide = SquatGuide()
        self.standards = SquatStandards()
        self.calibration_mode = True
        self.calibration_count = 0
        self.target_squat_area = None
        self.rep_count = 0
        self.current_phase = "STANDING"
        self.voice = VoiceFeedback()
        
        # ë°ì´í„° ì €ì¥ ê²½ë¡œ ì„¤ì • ë° ìƒì„±
        self.data_path = os.path.join(os.path.expanduser('~'), 'squat_data')
        for folder in ['daily', 'weekly', 'monthly']:
            path = os.path.join(self.data_path, folder)
            os.makedirs(path, exist_ok=True)

    def _calculate_joint_angles(self, landmarks) -> Dict[str, float]:
        """ì£¼ìš” ê´€ì ˆ ê°ë„ ê³„ì‚°"""
        def calculate_angle(a, b, c) -> float:
            a = np.array([a.x, a.y])
            b = np.array([b.x, b.y])
            c = np.array([c.x, c.y])
            
            radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - \
                     np.arctan2(a[1]-b[1], a[0]-b[0])
            angle = np.abs(radians * 180.0 / np.pi)
            
            if angle > 180.0:
                angle = 360 - angle
            return angle

        # ì£¼ìš” ê´€ì ˆ í¬ì¸íŠ¸ ì¶”ì¶œ
        hip = landmarks[self.mp_pose.PoseLandmark.LEFT_HIP.value]
        knee = landmarks[self.mp_pose.PoseLandmark.LEFT_KNEE.value]
        ankle = landmarks[self.mp_pose.PoseLandmark.LEFT_ANKLE.value]
        shoulder = landmarks[self.mp_pose.PoseLandmark.LEFT_SHOULDER.value]

        # ê°ë„ ê³„ì‚°
        hip_angle = calculate_angle(shoulder, hip, knee)
        knee_angle = calculate_angle(hip, knee, ankle)

        return {
            'hip': hip_angle,
            'knee': knee_angle
        }

    def _is_valid_squat_position(self, landmarks) -> bool:
        """ì˜¬ë°”ë¥¸ ìŠ¤ì¿¼íŠ¸ ìì„¸ì¸ì§€ í™•ì¸"""
        angles = self._calculate_joint_angles(landmarks)
        
        # ë³‘ë ¬ ìŠ¤ì¿¼íŠ¸ ê¸°ì¤€ì— ë§ëŠ”ì§€ í™•ì¸
        hip_in_range = abs(angles['hip'] - self.standards.PARALLEL['hip_angle']) <= self.standards.PARALLEL['tolerance']
        knee_in_range = abs(angles['knee'] - self.standards.PARALLEL['knee_angle']) <= self.standards.PARALLEL['tolerance']
        
        return hip_in_range and knee_in_range

    def _draw_landmarks(self, image: np.ndarray, landmarks: List) -> None:
        """ê´€ì ˆ í¬ì¸íŠ¸ì™€ ìŠ¤ì¼ˆë ˆí†¤ ì‹œê°í™”"""
        height, width = image.shape[:2]
        
        # ìŠ¤ì¼ˆë ˆí†¤ ì—°ê²°ì„  ê·¸ë¦¬ê¸°
        connections = self.mp_pose.POSE_CONNECTIONS
        for connection in connections:
            start_idx = connection[0]
            end_idx = connection[1]
            
            start_point = (int(landmarks[start_idx].x * width), 
                         int(landmarks[start_idx].y * height))
            end_point = (int(landmarks[end_idx].x * width), 
                        int(landmarks[end_idx].y * height))
            
            cv2.line(image, start_point, end_point, (0, 255, 0), 2)
        
        # ê´€ì ˆ í¬ì¸íŠ¸ ê·¸ë¦¬ê¸°
        for idx, landmark in enumerate(landmarks):
            pos = (int(landmark.x * width), int(landmark.y * height))
            cv2.circle(image, pos, 5, (0, 0, 255), -1)
            
            # ì£¼ìš” ê´€ì ˆ ê°ë„ í‘œì‹œ
            if idx in [self.mp_pose.PoseLandmark.LEFT_HIP.value,
                      self.mp_pose.PoseLandmark.LEFT_KNEE.value,
                      self.mp_pose.PoseLandmark.LEFT_ANKLE.value]:
                angles = self._calculate_joint_angles(landmarks)
                if idx == self.mp_pose.PoseLandmark.LEFT_HIP.value:
                    angle_text = f"Hip: {angles['hip']:.1f}Â°"
                elif idx == self.mp_pose.PoseLandmark.LEFT_KNEE.value:
                    angle_text = f"Knee: {angles['knee']:.1f}Â°"
                else:
                    continue
                    
                cv2.putText(image, angle_text,
                           (pos[0] + 10, pos[1]), 
                           cv2.FONT_HERSHEY_SIMPLEX, 
                           0.5, (255, 255, 255), 1)

    def _analyze_squat_phase(self, angles: Dict[str, float], landmarks: List) -> Dict:
        """ìŠ¤ì¿¼íŠ¸ ë‹¨ê³„ ë¶„ì„ ë° í”¼ë“œë°± ìƒì„±"""
        result = {
            'is_correct': False,
            'feedback': '',
            'score': 0
        }

        # í˜„ì¬ ì—‰ë©ì´ ë†’ì´ ê³„ì‚°
        hip_height = landmarks[self.mp_pose.PoseLandmark.LEFT_HIP.value].y

        # ë‹¨ê³„ íŒë‹¨
        if angles['hip'] > 160:  # ì„œìˆëŠ” ìì„¸
            self.current_phase = "STANDING"
            if not hasattr(self, 'prev_hip_height'):
                self.prev_hip_height = hip_height
        elif angles['hip'] < 100:  # ìŠ¤ì¿¼íŠ¸ ìì„¸
            self.current_phase = "SQUAT"
        
        result['phase'] = self.current_phase

        # ìì„¸ ë¶„ì„
        if self.current_phase == "SQUAT":
            # ë³‘ë ¬ ìŠ¤ì¿¼íŠ¸ ê¸°ì¤€ ì²´í¬
            hip_deviation = abs(angles['hip'] - self.standards.PARALLEL['hip_angle'])
            knee_deviation = abs(angles['knee'] - self.standards.PARALLEL['knee_angle'])
            
            # ì ìˆ˜ ê³„ì‚° (100ì  ë§Œì )
            angle_score = max(0, 100 - (hip_deviation + knee_deviation))
            result['score'] = angle_score

            # í”¼ë“œë°± ìƒì„±
            if angle_score >= 90:
                result['is_correct'] = True
                result['feedback'] = "Good!"
            else:
                result['feedback'] = "Try again!"

            # ë°˜ë³µ íšŸìˆ˜ ì—…ë°ì´íŠ¸
            if not hasattr(self, 'rep_counted'):
                self.rep_counted = False
            
            if angle_score >= 90 and not self.rep_counted:
                self.rep_count += 1
                self.rep_counted = True
                
        elif self.current_phase == "STANDING":
            self.rep_counted = False
            result['feedback'] = "Ready"
            result['is_correct'] = True

        return result

    def analyze_frame(self, frame: np.ndarray) -> Tuple[np.ndarray, Dict]:
        """í”„ë ˆì„ ë¶„ì„ ë° í”¼ë“œë°± ìƒì„±"""
        # BGRì„ RGBë¡œ ë³€í™˜
        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        image.flags.writeable = False
        results = self.pose.process(image)
        image.flags.writeable = True
        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)

        if not results.pose_landmarks:
            return image, {
                'is_correct': False,
                'feedback': 'No pose detected. Please stand in the frame.',
                'phase': 'UNKNOWN'
            }

        # ê³¨ê²© ê·¸ë¦¬ê¸°
        self._draw_landmarks(image, results.pose_landmarks.landmark)

        # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ëª¨ë“œ ì²˜ë¦¬
        if self.calibration_mode:
            return self._handle_calibration(image, results.pose_landmarks.landmark)

        # ì¼ë°˜ ë¶„ì„ ëª¨ë“œ
        return self._analyze_regular_squat(image, results.pose_landmarks.landmark)

    def _handle_calibration(self, image: np.ndarray, landmarks: List) -> Tuple[np.ndarray, Dict]:
        """ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì²˜ë¦¬"""
        if self.calibration_count >= 5:
            self.calibration_mode = False
            self.target_squat_area = self._calculate_target_area(landmarks)
            self.voice.speak("Calibration complete")
            return image, {
                'is_correct': True,
                'feedback': 'Calibration complete! Ready for workout.',
                'phase': 'CALIBRATED'
            }

        if self._is_valid_squat_position(landmarks):
            self.calibration_count += 1
            self.voice.speak(f"Good form {self.calibration_count}")
            feedback = f'Calibration rep {self.calibration_count}/5 recorded'
        else:
            feedback = 'Perform a proper squat for calibration'

        # ê°€ì´ë“œë¼ì¸ ê·¸ë¦¬ê¸°
        image = self.guide.draw_guide_area(image, landmarks, self.target_squat_area)
        return image, {
            'is_correct': False,
            'feedback': feedback,
            'phase': 'CALIBRATING'
        }

    def _analyze_regular_squat(self, image: np.ndarray, landmarks: List) -> Tuple[np.ndarray, Dict]:
        """ì¼ë°˜ ìŠ¤ì¿¼íŠ¸ ë¶„ì„"""
        angles = self._calculate_joint_angles(landmarks)
        in_target_area = self._is_in_target_area(landmarks)
        
        # ìŠ¤ì¿¼íŠ¸ ìì„¸ ë¶„ì„
        phase_feedback = self._analyze_squat_phase(angles, landmarks)
        
        # ê°€ì´ë“œë¼ì¸ ê·¸ë¦¬ê¸°
        image = self.guide.draw_guide_area(image, landmarks, self.target_squat_area)

        # í”¼ë“œë°± ìƒì„±
        if in_target_area and phase_feedback['is_correct']:
            self.voice.speak("Good!")
            feedback = "Good!"
        else:
            self.voice.speak("Try again!")
            feedback = "Try again!"

        return image, {
            'is_correct': in_target_area and phase_feedback['is_correct'],
            'feedback': feedback,
            'phase': self.current_phase,
            'angles': angles,
            'score': phase_feedback.get('score', 0)
        }

    def _calculate_target_area(self, landmarks) -> Dict:
        """ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹œ ê°€ìƒì˜ ì˜ì ëª¨ì–‘ì„ ì •ì˜"""
        self.guide.target_area = {
            'hip': landmarks[self.mp_pose.PoseLandmark.LEFT_HIP.value],
            'knee': landmarks[self.mp_pose.PoseLandmark.LEFT_KNEE.value],
            'ankle': landmarks[self.mp_pose.PoseLandmark.LEFT_ANKLE.value]
        }
        return self.guide.target_area

    def _is_in_target_area(self, landmarks) -> bool:
        """í˜„ì¬ ìì„¸ê°€ ê°€ìƒì˜ ì˜ì ëª¨ì–‘ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸"""
        if not self.guide.target_area:
            return False

        # í˜„ì¬ í™ ì¢Œí‘œ
        current_hip = landmarks[self.mp_pose.PoseLandmark.LEFT_HIP.value]
        target_hip = self.guide.target_area['hip']

        # ìœ„ì¹˜ ì˜¤ì°¨ í—ˆìš© ë²”ìœ„ ì„¤ì •
        tolerance = 0.05  # ìœ„ì¹˜ í—ˆìš© ì˜¤ì°¨

        # í™ì˜ ìœ„ì¹˜ ì°¨ì´ ê³„ì‚°
        hip_diff = np.hypot(current_hip.x - target_hip.x, current_hip.y - target_hip.y)

        # í™ì´ ê°€ì´ë“œ ì˜ì—­ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸
        return hip_diff < tolerance

    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        self.voice.cleanup()

def main():
    st.title("AI SmartSquat Pro ğŸ‹ï¸â€â™‚ï¸")
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'analyzer' not in st.session_state:
        st.session_state.analyzer = EnhancedSquatAnalysisEngine()
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.header("Settings âš™ï¸")
        show_skeleton = st.checkbox("Show Skeleton ğŸ¦´", True)
        show_guide = st.checkbox("Show Guide Area ğŸ¯", True)
        show_angles = st.checkbox("Show Joint Angles ğŸ“", True)

    # ë©”ì¸ ì»¨íŠ¸ë¡¤
    cols = st.columns(4)
    
    if cols[0].button("ğŸ¯ Start Calibration", use_container_width=True):
        st.session_state.analyzer = EnhancedSquatAnalysisEngine()
        st.info("Please perform 5 squats to set your baseline.")
    
    if cols[1].button("ğŸ“¹ Camera Check", use_container_width=True):
        st.session_state.camera_check = True
    
    if cols[2].button("ğŸš€ Start Workout", use_container_width=True):
        st.session_state.workout_active = True
    
    if cols[3].button("â¹ï¸ Stop", use_container_width=True):
        if hasattr(st.session_state.analyzer, 'cleanup'):
            st.session_state.analyzer.cleanup()
        st.session_state.workout_active = False

    # ì¹´ë©”ë¼ í”¼ë“œ
    FRAME_WINDOW = st.empty()
    
    # Progress í‘œì‹œ
    progress_cols = st.columns(2)
    rep_count = progress_cols[0].empty()
    phase_indicator = progress_cols[1].empty()

    cap = cv2.VideoCapture(0)

    try:
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                st.error("Failed to capture video frame")
                break

            # í”„ë ˆì„ ë¶„ì„
            processed_frame, feedback = st.session_state.analyzer.analyze_frame(frame)
            
            # í”¼ë“œë°± í‘œì‹œ
            feedback_color = (0, 255, 0) if feedback['is_correct'] else (0, 0, 255)
            cv2.putText(
                processed_frame,
                feedback['feedback'],
                (50, 50),
                cv2.FONT_HERSHEY_SIMPLEX,
                1,
                feedback_color,
                2
            )

            # Progress ì—…ë°ì´íŠ¸
            rep_count.metric("Reps Completed ğŸ”„", st.session_state.analyzer.rep_count)
            phase_indicator.info(f"Current Phase: {feedback['phase']}")

            # ìŠ¤ì¼ˆë ˆí†¤ê³¼ ê°€ì´ë“œ í‘œì‹œ ì„¤ì • ì ìš©
            if not show_skeleton:
                # ìŠ¤ì¼ˆë ˆí†¤ ìˆ¨ê¸°ê¸° (ì´ë¯¸ì§€ì—ì„œ ì œê±°í•˜ëŠ” ë¡œì§ í•„ìš”)
                pass
            if not show_guide:
                # ê°€ì´ë“œë¼ì¸ ìˆ¨ê¸°ê¸° (ì´ë¯¸ì§€ì—ì„œ ì œê±°í•˜ëŠ” ë¡œì§ í•„ìš”)
                pass

            FRAME_WINDOW.image(processed_frame, channels="BGR")

            # ESC í‚¤ë¡œ ì¢…ë£Œ
            if cv2.waitKey(1) & 0xFF == 27:
                break

    finally:
        cap.release()
        if hasattr(st.session_state.analyzer, 'cleanup'):
            st.session_state.analyzer.cleanup()

if __name__ == "__main__":
    main()
